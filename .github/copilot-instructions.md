# TCS Stock Forecast - AI Agent Instructions

## Project Overview
This is a time-series forecasting system for TCS.NS (Tata Consultancy Services) stock prices. The pipeline combines data cleaning, feature engineering, and dual ML models (short-term: 1-day, long-term: ~63-day predictions) with a FastAPI service for live predictions.

**Key artifact files**: `run_all.py` (orchestrator), `src/data/`, `src/features/`, `src/api/predict_simple.py` (FastAPI endpoints).

## Architecture: Data Flow & Boundaries

```
Raw Data → Clean & QC → Features → Datasets → Train → Predict → API
(Daily+Hourly)         (Daily)    (Horizons)  (Models)          (JSON)
```

### Core Components

1. **Data Layer** (`src/data/`)
   - `db_utils.py`: PostgreSQL connection & SQL queries (single source for DB access)
   - `cleaning.py`: Loads raw→clean, dedupes hourly, fills missing adj_close, drops nulls
   - `data_pipeline.py`: Quality checks & aggregations (not typically called directly)

2. **Feature Layer** (`src/features/features_daily.py`)
   - Computes lag returns, moving averages, momentum, volatility from cleaned daily data
   - Output: `features_daily` table; feature columns: `return_lag1-5`, `sma_7`, `sma_21`, `mom_7`, `vol_14`, `volume`
   - **CRITICAL**: These 10 columns must match exactly in training & prediction (`FEATURE_COLS` in `src/api/predict_simple.py`)

3. **Model Layer** (`src/models/`)
   - Two scikit-learn models trained separately:
     - **Short**: Predicts `y_day1` (1-day return) → next business day
     - **Long**: Predicts `y_63` (63-day return) → ~63 business days ahead
   - Saved as `.pkl` files in `models/` directory
   - Evaluation metrics in `reports/evaluation_summary.csv` (MAE, RMSE, R²)

4. **API Layer** (`src/api/predict_simple.py`)
   - FastAPI app with two POST endpoints: `/predict/short`, `/predict/long`
   - Also GET wrappers for browser access
   - Returns: `horizon`, `feature_date`, `predict_date`, `pred_return`, `est_future_close`, `pct_return`
   - Warns if feature data is stale (model date ≠ system date)

## CLI Conventions (Essential!)

**Every module follows this pattern**:
```bash
python -m src.data.cleaning [show|write] --ticker TCS.NS
python -m src.features.features_daily [show|run|write] --ticker TCS.NS
python -m src.models.build_dataset [show|write] --horizon [short|long|both]
```

- `show`: Load data, display sample (no writes, safe to test)
- `run`: Compute in-memory result, display (intermediate step, features only)
- `write`: Persist to database or disk (final step, may overwrite)

**Running full pipeline**:
```bash
PYTHONPATH=. python run_all.py show   # Preview without changes
PYTHONPATH=. python run_all.py run    # Execute full pipeline (idempotent)
```

## Database Setup

- **Engine**: PostgreSQL via SQLAlchemy
- **Required env var**: `DATABASE_URL` (e.g., `postgresql://user:pass@localhost/forecast_db`)
- **Tables**:
  - `raw_daily_prices`, `raw_hourly_prices` (original data)
  - `raw_daily_prices_clean`, `raw_hourly_prices_clean` (cleaned)
  - `features_daily` (computed features)
  - `dataset_short`, `dataset_long` (model datasets for inference)
- **Key pattern**: Use `db_utils.get_engine()` everywhere—single connection factory

## Logging

Global logger configured in `src/config/logging_config.py`:
- Level: `INFO`
- Output: Console + file (`logs/tcs-stock.log`)
- Import: `from src.config.logging_config import logger`

## Critical Patterns

### Index & Column Handling
- **Daily**: Index is `pd.Timestamp.date` (Python date object), column `date` when writing
- **Hourly**: Index is `pd.Timestamp` (naive, no timezone), column `ts` when writing
- Always reset index before `.to_sql()` to avoid duplicate columns

### Stale Feature Detection
The API checks if `feature_date` (last row in feature table) ≠ system date, and returns a `note` field warning that predictions may be stale. This is normal behavior—user must run data refresh manually if needed.

### Feature Column Sync
`FEATURE_COLS` in `src/api/predict_simple.py` (hardcoded list of 10 columns) must exactly match:
1. Columns computed in `src/features/features_daily.py`
2. Columns in `dataset_short` and `dataset_long` used during training

Mismatch → shape errors in `.predict()`. Always check `src/api/predict_simple.py` line ~20 when adding features.

## Project Layout Essentials

- `run_all.py`: Entry point for full pipeline (orchestrates show→write sequence)
- `notebooks/FP_Pipeline_Daily_Hourly.ipynb`: Initial EDA & feature exploration
- `reports/final_report.ipynb`: Generated by `tools/create_final_report_nb.py`; loads predictions & plots
- `predictions/`: CSV outputs from model inference (`short_predictions.csv`, `long_predictions.csv`)
- `requirements.txt`: Dependencies (FastAPI, SQLAlchemy, scikit-learn, pandas, numpy)

## Typical Workflows

### Refresh Data & Retrain
```bash
# 1. Update raw data (external tool—not in this repo)
# 2. Clean & QC
PYTHONPATH=. python -m src.data.cleaning write --ticker TCS.NS

# 3. Recompute features
PYTHONPATH=. python -m src.features.features_daily write --ticker TCS.NS

# 4. Rebuild datasets & retrain
PYTHONPATH=. python run_all.py run
```

### Debug Feature Mismatch
1. Check latest feature row: `SELECT * FROM features_daily ORDER BY date DESC LIMIT 1;`
2. Verify column names match `FEATURE_COLS` in API
3. Rerun feature engineering: `python -m src.features.features_daily write --ticker TCS.NS`

### Generate Report
```bash
python tools/create_final_report_nb.py
# Creates reports/final_report.ipynb with predictions & plots
```

## Notes for AI Agents

- **Don't assume**: Check if tables exist & have data before writing; use `show` first
- **Env vars matter**: `DATABASE_URL` and `TICKER` (defaults to "TCS.NS") must be set
- **Feature stability**: Adding/removing features requires updating `FEATURE_COLS` AND retraining models
- **Timezone handling**: Hourly data is stored as naive timestamps (no UTC offset); keep it that way
- **Error handling**: Most modules log and continue; check logs for silent failures (`logs/tcs-stock.log`)
